{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dir = \"machine-learning-101-master/chapter2/train-mails\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dir = \"machine-learning-101-master/chapter2/test-mails\"\n",
    "w = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_dictionary(root_dir):\n",
    "    word_dic = []\n",
    "    emails = [os.path.join(root_dir, f) for f in os.listdir(root_dir)]\n",
    "    for mail in emails:\n",
    "        with open(mail) as m:\n",
    "            for line in m:\n",
    "                words = line.split()\n",
    "                word_dic += words\n",
    "    dictionary = Counter(word_dic)\n",
    "    dictionary2 = deepcopy(dictionary)\n",
    "    list_to_remove = dictionary.keys()\n",
    "    \n",
    "    for item in list_to_remove:\n",
    "        if item.isalpha() == False:\n",
    "            del dictionary2[item]\n",
    "        elif len(item) == 1:\n",
    "            del dictionary2[item]\n",
    "            \n",
    "    dictionary_final = dictionary2.most_common(w)\n",
    "    \n",
    "    return dictionary_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(mail_dir):\n",
    "    files = [os.path.join(mail_dir, f) for f in os.listdir(mail_dir)]\n",
    "    features_matrix = np.zeros((len(files), w))\n",
    "    train_labels = np.zeros(len(files))\n",
    "    count = 0\n",
    "    docId = 0\n",
    "   \n",
    "    for file in files:\n",
    "        with open(file) as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if i == 2:\n",
    "                    words = line.split()\n",
    "                    for word in words:\n",
    "                        wordId = 0\n",
    "                        for i, d in enumerate(dictionary):\n",
    "                            #print(i, d)\n",
    "                            if d[0] == word:\n",
    "                                wordId = i\n",
    "                                features_matrix[docId, wordId] = words.count(word)\n",
    "       \n",
    "            train_labels[docId] = 0\n",
    "            filepath = file.split('/')\n",
    "            token = filepath[len(filepath) - 1]\n",
    "            if token.startswith('spmsg'):\n",
    "                train_labels[docId] = 1\n",
    "                count += 1\n",
    "            docId += 1\n",
    "    return features_matrix, train_labels\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from copy import deepcopy\n",
    "dictionary = make_dictionary(train_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix, labels = extract_features(train_dir)\n",
    "test_feature_matrix, test_labels = extract_features(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = feature_matrix[:len(feature_matrix)//10]\n",
    "labels = labels[:len(labels)//10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our model\n",
    "from sklearn import svm\n",
    "model = svm.SVC(kernel=\"rbf\", C = 100, gamma = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/600/1*ptAi70_jY6gEOJRIgs3MMw.jpeg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from IPython.display import Image\n",
    "Image(url='https://cdn-images-1.medium.com/max/600/1*ptAi70_jY6gEOJRIgs3MMw.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "print('Training model')\n",
    "model.fit(feature_matrix, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://nlp.stanford.edu/IR-book/html/htmledition/img1260.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://nlp.stanford.edu/IR-book/html/htmledition/img1260.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict\n",
    "predicted_labels = model.predict(test_feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predicted = accuracy_score(test_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying with Support Vector Machine, accuracy: 50.000000%\n"
     ]
    }
   ],
   "source": [
    "print(\"Classifying with Support Vector Machine, accuracy: %f\"%(100 * accuracy_score(test_labels, predicted_labels))+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
